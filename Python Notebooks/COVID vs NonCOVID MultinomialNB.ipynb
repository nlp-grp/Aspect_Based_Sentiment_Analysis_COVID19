{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import gzip\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 1013\n",
    "np.random.seed(SEED)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import sparse\n",
    "import os\n",
    "import pickle\n",
    "import emoji\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_files_path = r'path'\n",
    "\n",
    "covid_train_data = []\n",
    "noncovid_train_data = []\n",
    "covid_train_labels = []\n",
    "noncovid_train_labels = []\n",
    "\n",
    "covid_train_data2 = []\n",
    "noncovid_train_data2 = []\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(covid_files_path,'r') as fin:\n",
    "        for line in fin:\n",
    "            tweet = json.loads(line)\n",
    "            covid_train_data.append(tweet['text'])\n",
    "            covid_train_labels.append(1)\n",
    "except:\n",
    "    print(\"Faulty file \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noncovid_files_path = r'path2'\n",
    "noncovid_files = glob.glob(noncovid_files_path)\n",
    "num_noncovid_tweets = 0\n",
    "\n",
    "for i in range(len(noncovid_files)):\n",
    "    print(\"opening file\", noncovid_files[i])\n",
    "    try:\n",
    "        with gzip.open(noncovid_files[i],'r') as fin:\n",
    "            for line in fin:\n",
    "                if num_noncovid_tweets < 27068:\n",
    "                    tweet = json.loads(line)\n",
    "                    noncovid_train_data.append(tweet['text'])\n",
    "                    noncovid_train_labels.append(0)\n",
    "                    num_noncovid_tweets += 1\n",
    "\n",
    "    except:\n",
    "        print(\"Faulty file \", noncovid_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[^ ]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "www_pat = r'www.[^ ]+'\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def tweet_cleaner_updated(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', bom_removed)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    stripped = re.sub(r'\\@w+','',stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in covid_train_data:\n",
    "    covid_train_data2.append(tweet_cleaner_updated(tweet))\n",
    "    \n",
    "for ntweet in noncovid_train_data:\n",
    "    noncovid_train_data2.append(tweet_cleaner_updated(ntweet))\n",
    "\n",
    "train_data = covid_train_data2 + noncovid_train_data2\n",
    "train_labels = covid_train_labels + noncovid_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(columns=['text','target'])\n",
    "my_df['text'] = train_data\n",
    "my_df['target'] = train_labels\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "cvec.fit(my_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_doc_matrix = cvec.transform(my_df[my_df.target == 0].text)\n",
    "pos_doc_matrix = cvec.transform(my_df[my_df.target == 1].text)\n",
    "neg_tf = np.sum(neg_doc_matrix,axis=0)\n",
    "pos_tf = np.sum(pos_doc_matrix,axis=0)\n",
    "neg = np.squeeze(np.asarray(neg_tf))\n",
    "pos = np.squeeze(np.asarray(pos_tf))\n",
    "term_freq_df = pd.DataFrame([neg,pos],columns=cvec.get_feature_names()).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_freq_df.columns = ['negative', 'positive']\n",
    "term_freq_df['total'] = term_freq_df['negative'] + term_freq_df['positive']\n",
    "term_freq_df.sort_values(by='total', ascending=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer(stop_words='english',max_features=10000)\n",
    "cvec.fit(my_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_matrix = cvec.transform(my_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_doc_matrix2 = cvec.transform(my_df[my_df.target == 0].text)\n",
    "pos_doc_matrix2 = cvec.transform(my_df[my_df.target == 1].text)\n",
    "neg_tf2 = np.sum(neg_doc_matrix2,axis=0)\n",
    "pos_tf2 = np.sum(pos_doc_matrix2,axis=0)\n",
    "neg2 = np.squeeze(np.asarray(neg_tf2))\n",
    "pos2 = np.squeeze(np.asarray(pos_tf2))\n",
    "term_freq_df2 = pd.DataFrame([neg2,pos2],columns=cvec.get_feature_names()).transpose()\n",
    "term_freq_df2.columns = ['negative', 'positive']\n",
    "term_freq_df2['total'] = term_freq_df2['negative'] + term_freq_df2['positive']\n",
    "term_freq_df2.sort_values(by='total', ascending=False).iloc[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus,test_corpus,train_labels,test_labels = train_test_split(train_data,train_labels,stratify=train_labels,test_size=0.25,random_state=1)\n",
    "train_texts, train_labels, test_texts, test_labels = train_corpus, train_labels, test_corpus, test_labels\n",
    "x_train, y_train, x_validation, y_validation = train_corpus,train_labels,test_corpus,test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_len0 = 0\n",
    "y_train_len1 = 1\n",
    "for label in y_train:\n",
    "    if label == 1:\n",
    "        y_train_len1 += 1\n",
    "    else:\n",
    "        y_train_len0 += 1\n",
    "        \n",
    "y_val_len0 = 0\n",
    "y_val_len1 = 0\n",
    "for label in y_validation:\n",
    "    if label == 1:\n",
    "        y_val_len1 += 1\n",
    "    else:\n",
    "        y_val_len0 += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_train),\n",
    "                                                                             (y_train_len0 / (len(x_train)*1.))*100,\n",
    "                                                                            (y_train_len1 / (len(x_train)*1.))*100))\n",
    "       \n",
    "                                                                            \n",
    "print(\"Validation set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_validation),\n",
    "                                                                             (y_val_len0 / (len(x_validation)))*100,\n",
    "                                                                            (y_val_len1 / (len(x_validation)))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    if y_val_len0 / (len(x_test)*1.) > 0.5:\n",
    "        null_accuracy =  y_val_len1/ (len(x_test)*1.)\n",
    "    else:\n",
    "        null_accuracy = 1. - (y_val_len1 / (len(x_test)*1.))\n",
    "    #t0 = time.time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    #train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print (\"null accuracy: {0:.2f}%\".format(null_accuracy*100))\n",
    "    print (\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
    "    if accuracy > null_accuracy:\n",
    "        print (\"model is {0:.2f}% more accurate than null accuracy\".format((accuracy-null_accuracy)*100))\n",
    "    elif accuracy == null_accuracy:\n",
    "        print (\"model has the same accuracy with the null accuracy\")\n",
    "    else:\n",
    "        print (\"model is {0:.2f}% less accurate than null accuracy\".format((null_accuracy-accuracy)*100))\n",
    "    print (\"-\"*80)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "cvec = CountVectorizer()\n",
    "lr = MultinomialNB()\n",
    "n_features = np.arange(10000,48001,10000)\n",
    "\n",
    "def nfeature_accuracy_checker(vectorizer=cvec, n_features=n_features, stop_words=None, ngram_range=(1, 1), classifier=lr):\n",
    "    result = []\n",
    "    print (classifier)\n",
    "    print (\"\\n\")\n",
    "    for n in n_features:\n",
    "        vectorizer.set_params(stop_words=stop_words, max_features=n, ngram_range=ngram_range)\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "        print(\"Validation result for {} features\".format(n))\n",
    "        nfeature_accuracy = accuracy_summary(checker_pipeline, x_train, y_train, x_validation, y_validation)\n",
    "        result.append((n,nfeature_accuracy))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "z = frozenset(list(term_freq_df.sort_values(by='total', ascending=False).iloc[:3].index))\n",
    "c = frozenset(list(term_freq_df.sort_values(by='total', ascending=False).iloc[4:11].index))\n",
    "listofsets = [z,c]\n",
    "a = frozenset.union(*listofsets)\n",
    "b = text.ENGLISH_STOP_WORDS\n",
    "set(a).issubset(set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESULT FOR UNIGRAM WITHOUT STOP WORDS\\n\")\n",
    "feature_result_wosw = nfeature_accuracy_checker(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESULT FOR UNIGRAM WITH STOP WORDS\\n\")\n",
    "feature_result_ug = nfeature_accuracy_checker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESULT FOR UNIGRAM WITHOUT CUSTOM STOP WORDS (Top 10 frequent words)\\n\")\n",
    "feature_result_wocsw = nfeature_accuracy_checker(stop_words=my_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeatures_plot_ug = pd.DataFrame(feature_result_ug,columns=['nfeatures','validation_accuracy'])\n",
    "nfeatures_plot_ug_wocsw = pd.DataFrame(feature_result_wocsw,columns=['nfeatures','validation_accuracy'])\n",
    "nfeatures_plot_ug_wosw = pd.DataFrame(feature_result_wosw,columns=['nfeatures','validation_accuracy'])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(nfeatures_plot_ug.nfeatures, nfeatures_plot_ug.validation_accuracy, label='with stop words')\n",
    "plt.plot(nfeatures_plot_ug_wocsw.nfeatures, nfeatures_plot_ug_wocsw.validation_accuracy,label='without custom stop words')\n",
    "plt.plot(nfeatures_plot_ug_wosw.nfeatures, nfeatures_plot_ug_wosw.validation_accuracy,label='without stop words')\n",
    "plt.title(\"Without stop words VS With stop words (Unigram): Accuracy\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"Validation set accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print (\"RESULT FOR UNIGRAM WITHOUT CUSTOM STOP WORDS (Tfidf)\\n\")\n",
    "feature_result_ugt = nfeature_accuracy_checker(stop_words = my_stop_words,vectorizer=tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print (\"RESULT FOR UNIGRAM WITHOUT STOP WORDS (Tfidf)\\n\")\n",
    "feature_result_ugt2 = nfeature_accuracy_checker(stop_words = 'english',vectorizer=tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print (\"RESULT FOR UNIGRAM WITH STOP WORDS (Tfidf)\\n\")\n",
    "feature_result_ugt3 = nfeature_accuracy_checker(vectorizer=tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeatures_plot_ugt = pd.DataFrame(feature_result_ugt,columns=['nfeatures','validation_accuracy'])\n",
    "nfeatures_plot_ugt2 = pd.DataFrame(feature_result_ugt2,columns=['nfeatures','validation_accuracy'])\n",
    "nfeatures_plot_ugt3 = pd.DataFrame(feature_result_ugt3,columns=['nfeatures','validation_accuracy'])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(nfeatures_plot_ugt.nfeatures, nfeatures_plot_ugt.validation_accuracy, label='without custom stop words')\n",
    "plt.plot(nfeatures_plot_ugt2.nfeatures, nfeatures_plot_ugt2.validation_accuracy,label='without stop words')\n",
    "plt.plot(nfeatures_plot_ugt3.nfeatures, nfeatures_plot_ugt3.validation_accuracy,label='with stop words')\n",
    "plt.title(\" tfidf Without stop words VS With stop words (Unigram): Accuracy\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"Validation set accuracy\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
